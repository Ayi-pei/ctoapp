（A）可跑在 Supabase Edge Functions 的采集任务代码（每分钟调用 CoinGecko 并把标准化结果 upsert 到 market_summary_data），（B）用于冷启动的初始化 SQL 函数（在服务端生成初始 K 线或接受历史 K 线并批量写入 market_kline_data），以及 （C）如何在 Supabase Scheduler 上部署 / 测试 / 前端订阅 的步骤。你拿到之后可以直接部署或按需改小细节。下面分块给出 —— 我会把每块写得直接可用，并附上部署和测试步骤。

A. Edge Function：fetch-market-summary（每分钟轮询并 upsert）

目标：每分钟调用 CoinGecko（主）/CoinDesk（备用），把标准格式的 market summary 写入 market_summary_data。

文件：functions/fetch-market-summary/index.ts

// Edge Function (Deno / Supabase Edge Functions style)
// put this under functions/fetch-market-summary
import { createClient } from '@supabase/supabase-js'

const SUPABASE_URL = Deno.env.get('SUPABASE_URL')!;
const SUPABASE_SERVICE_ROLE_KEY = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;

const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY, {
  auth: { persistSession: false }
});

// map your pairs to coingecko ids
const PAIR_TO_CG_ID: Record<string, string> = {
  'BTC/USDT': 'bitcoin',
  'ETH/USDT': 'ethereum',
  'SOL/USDT': 'solana',
  'XRP/USDT': 'ripple',
  // ... 完善列表
};

export default async function handler(req: Request) {
  try {
    const pairs = Object.keys(PAIR_TO_CG_ID);
    const ids = pairs.map(p => PAIR_TO_CG_ID[p]).join(',');
    // 调用 CoinGecko 批量接口（simple/price）
    const cgUrl = `https://api.coingecko.com/api/v3/simple/price?ids=${encodeURIComponent(ids)}&vs_currencies=usd&include_24hr_change=true&include_24hr_vol=true`;
    const cgResp = await fetch(cgUrl);
    if (!cgResp.ok) {
      console.warn('CoinGecko failed', cgResp.status);
      return new Response(JSON.stringify({ error: 'CoinGecko fetch failed' }), { status: 502 });
    }
    const cgJson = await cgResp.json();

    const upserts = pairs.map(pair => {
      const id = PAIR_TO_CG_ID[pair];
      const price = cgJson[id]?.usd ?? null;
      const change = cgJson[id]?.usd_24h_change ?? 0;
      const volume = cgJson[id]?.usd_24h_vol ?? 0;
      return {
        pair,
        price,
        change,
        volume,
        high: null,
        low: null,
        source: 'coingecko',
        updated_at: new Date().toISOString()
      };
    });

    // 批量 upsert 到 market_summary_data（主键: pair）
    const { error } = await supabase
      .from('market_summary_data')
      .upsert(upserts, { onConflict: ['pair'] });

    if (error) {
      console.error('Supabase upsert error', error);
      return new Response(JSON.stringify({ error: error.message }), { status: 500 });
    }

    return new Response(JSON.stringify({ ok: true }), { status: 200 });

  } catch (err) {
    console.error('fetch-market-summary handler error', err);
    return new Response(JSON.stringify({ error: String(err) }), { status: 500 });
  }
}


部署 / 调度建议

在 Supabase 控制台创建 Edge Function，粘贴上面代码。

在 Project Settings -> Environment Variables 设置 SUPABASE_URL 与 SUPABASE_SERVICE_ROLE_KEY（service role）。

使用 Supabase Scheduler（或你常用的 cron）把这个函数设为 每分钟 执行一次。

日志观察：在 Edge Function 的日志里检查调用是否成功；并在 Supabase 表中查看 market_summary_data 是否有更新行。

B. 冷启动（initialize）SQL 函数 —— 在服务端生成初始 4 小时 K 线

目标：当 market_kline_data 为空时，后端可调用这个函数生成初始模拟数据（也可改为接收历史 API 的数据并插入）。

SQL（在 Supabase SQL Editor 中运行）

-- 初始化函数：基于基准价格生成过去 N 分钟的分钟级 K 线
create or replace function initialize_market_kline(p_pair text, p_base_price numeric, p_minutes int default 240)
returns void language plpgsql as $$
declare
  t int;
  cur_ts bigint := extract(epoch from now())::bigint - (p_minutes * 60);
  price numeric := p_base_price;
  o numeric;
  h numeric;
  l numeric;
  c numeric;
begin
  for t in 1..p_minutes loop
    price := price * (1 + (random() - 0.5) * 0.002); -- 小幅随机波动
    o := price * (0.999 + random()*0.002);
    c := price;
    h := greatest(o, c) * (1 + random()*0.001);
    l := least(o, c) * (1 - random()*0.001);

    insert into market_kline_data(trading_pair, time, open, high, low, close, volume, is_intervened, created_at)
    values (p_pair, cur_ts * 1000, o, h, l, c, (100 + random()*50), false, to_timestamp(cur_ts));
    cur_ts := cur_ts + 60;
  end loop;
end;
$$;


如何调用（SQL 或 Edge Function 调用）

-- 例如：用基准价 30000 初始化 BTC/USDT，4 小时（240 分钟）
select initialize_market_kline('BTC/USDT', 30000, 240);


进阶建议：更真实的做法是从历史 API（交易所或 AlphaVantage/Historical options 等）拉取真实 minute K 线然后批量插入，而不是随机生成。上面函数仅作为“立即可用的冷启动”方案。

C. 后端延迟队列 + 干预合并（示例逻辑）

目标：把 market_kline_raw（实时写入的原始行）在延迟后写入 market_kline_data，写入前判断 market_interventions 并覆盖。

伪代码（Node / Edge Function 可用）

// 伪代码示例：runDelayWorker()
const delayMs = 60 * 1000 * DELAY_MINUTES; // e.g. 2分钟
// 1) 找到 raw 中 time <= now()-delayMs 的行（按 trading_pair 分页处理）
const { data: rows } = await supabase.from('market_kline_raw')
  .select('*')
  .lte('time', Date.now() - delayMs);

// 2) 逐行处理（可并行分批）
for (const r of rows) {
  // 查询是否有干预在 r.time 覆盖该交易对
  const { data: intv } = await supabase.from('market_interventions')
    .select('*')
    .eq('trading_pair', r.trading_pair)
    .lte('start_time', new Date(r.time))
    .gte('end_time', new Date(r.time))
    .order('priority', { ascending: false })
    .limit(1);

  let final = { ...r, is_intervened: false };
  if (intv && intv.length) {
    const rule = intv[0].rule;
    // apply rule: 支持 forcePrice / priceMultiplier / priceOffset
    if (rule.forcePrice) {
      final.open = final.high = final.low = final.close = rule.forcePrice;
    } else if (rule.priceMultiplier) {
      final.open *= rule.priceMultiplier;
      final.high *= rule.priceMultiplier;
      final.low *= rule.priceMultiplier;
      final.close *= rule.priceMultiplier;
    } else if (rule.priceOffset) {
      final.open += rule.priceOffset; /* ... */
    }
    final.is_intervened = true;
  }

  // upsert 到 market_kline_data
  await supabase.from('market_kline_data').upsert({
    trading_pair: final.trading_pair,
    time: final.time,
    open: final.open,
    high: final.high,
    low: final.low,
    close: final.close,
    volume: final.volume,
    is_intervened: final.is_intervened
  }, { onConflict: ['trading_pair','time'] });
}


部署建议

把这段逻辑放在一个可定时 / 持久运行的 Job（比如每 5~10 秒触发一次，或更稳妥地每分钟处理一批），并确保单线程处理同一时间段以防并发覆写。

日志：记录每次写入的 is_intervened true 行，便于审计。

D. 前端：订阅 Supabase Realtime（示例 Hook）

前端只需订阅 market_summary_data 与 market_kline_data 的变更。下面给你一个简化的 React Hook 示例（你可以把它集成到现有的 market-data-context.tsx）：

import { createClient } from '@supabase/supabase-js';
import { useEffect } from 'react';
const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);

export function useMarketRealtime(onSummary, onKline) {
  useEffect(() => {
    const s1 = supabase
      .from('market_summary_data')
      .on('UPDATE', payload => onSummary(payload.new))
      .on('INSERT', payload => onSummary(payload.new))
      .subscribe();

    const s2 = supabase
      .from('market_kline_data')
      .on('INSERT', payload => onKline(payload.new))
      .subscribe();

    return () => {
      supabase.removeSubscription(s1);
      supabase.removeSubscription(s2);
    };
  }, [onSummary, onKline]);
}

E. 测试计划（快速验证步骤）

建表：在 Supabase SQL Editor 执行上面的建表 SQL。

部署 Edge Function：把 fetch-market-summary 部署并用“立即运行”按钮测试。

查看表：确认 market_summary_data 有行并且 updated_at 被刷新。

冷启动：在 SQL Editor 运行 select initialize_market_kline('BTC/USDT', 30000, 240);，并在 market_kline_data 表里看到 240 条记录。

干预测试：往 market_interventions 插入一条短期规则，手动执行延迟写入逻辑（或模拟一个 market_kline_raw 后触发 worker），查看 market_kline_data 被正确覆盖且 is_intervened = true。

前端订阅：前端对 market_summary_data + market_kline_data 订阅，观察实时推送。

F. 小结（为什么这套方案对你最合适）

前端轻量：不再承担 polling 与计算负担，用户设备更省电、不卡顿。

一致性：所有用户收到相同的、由后端生成或经管理员干预的“延迟数据”。

可审计：原始 market_kline_raw 保存真实 API，market_kline_data 保存展示数据，market_interventions 保存规则，审计方便。

弹性扩展：后端可以根据负载把写入/广播改为分层队列或 worker 集群。

冷启动/初始化 K 线的 Edge Function（服务端实现）**给你：它既能 （A）根据传入基准价生成 4 小时的模拟分钟级 K 线，也能 （B）接受外部历史 K 线数据（JSON 列表）并批量写入。这样你可以：

在没有历史数据时，服务器端一键填充（避免前端卡死的生成逻辑）；

或者把第三方历史数据抓取放到后端（或人工上传 CSV/JSON），通过该接口一次性导入到 market_kline_data。

下面是可直接部署到 Supabase Edge Functions 的代码、环境变量、示例调用与说明 — 直接照着跑即可。

✅ 文件：functions/initialize-market-kline/index.ts

（Deno / Supabase Edge Function 风格 — 放到 Supabase Functions 下）

// functions/initialize-market-kline/index.ts
import { createClient } from '@supabase/supabase-js'

const SUPABASE_URL = Deno.env.get('SUPABASE_URL')!;
const SUPABASE_SERVICE_ROLE_KEY = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;

if (!SUPABASE_URL || !SUPABASE_SERVICE_ROLE_KEY) {
  console.error('Missing SUPABASE env vars');
}

const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY, {
  auth: { persistSession: false }
});

// Utility: deterministic-ish pseudo-random based on seed
function mulberry32(a: number) {
  return function() {
    var t = a += 0x6D2B79F5;
    t = Math.imul(t ^ t >>> 15, t | 1);
    t ^= t + Math.imul(t ^ t >>> 7, t | 61);
    return ((t ^ t >>> 14) >>> 0) / 4294967296;
  }
}

/**
 * Request body options:
 * {
 *   mode: 'generate' | 'upload',
 *   pair: 'BTC/USDT',
 *   minutes: 240,               // optional, default 240 (4 hours)
 *   basePrice: 30000,           // required for generate
 *   seed: 1234,                 // optional deterministic seed
 *   data: [{ time: 167..., open, high, low, close, volume }, ...] // for upload
 * }
 */
export default async function handler(req: Request) {
  try {
    if (req.method !== 'POST') {
      return new Response(JSON.stringify({ error: 'POST required' }), { status: 405 });
    }

    const payload = await req.json().catch(() => null);
    if (!payload) {
      return new Response(JSON.stringify({ error: 'Invalid JSON body' }), { status: 400 });
    }

    const { mode = 'generate', pair, minutes = 240, basePrice, seed } = payload;

    if (!pair) {
      return new Response(JSON.stringify({ error: 'pair is required' }), { status: 400 });
    }

    if (mode === 'upload') {
      const arr = payload.data;
      if (!Array.isArray(arr) || arr.length === 0) {
        return new Response(JSON.stringify({ error: 'data array required for upload mode' }), { status: 400 });
      }

      // Normalize and bulk insert (chunked)
      const rows = arr.map((d: any) => ({
        trading_pair: pair,
        time: Number(d.time),
        open: Number(d.open),
        high: Number(d.high),
        low: Number(d.low),
        close: Number(d.close),
        volume: d.volume != null ? Number(d.volume) : null,
        is_intervened: false,
        created_at: new Date().toISOString()
      }));

      // chunk to avoid very large payloads
      const CHUNK = 1000;
      for (let i = 0; i < rows.length; i += CHUNK) {
        const slice = rows.slice(i, i + CHUNK);
        const { error } = await supabase.from('market_kline_data').insert(slice, { returning: 'minimal' });
        if (error) {
          console.error('Supabase insert chunk error', error);
          return new Response(JSON.stringify({ error: error.message }), { status: 500 });
        }
      }

      return new Response(JSON.stringify({ ok: true, inserted: rows.length }), { status: 200 });
    }

    // mode === 'generate'
    if (typeof basePrice !== 'number' || !(basePrice > 0)) {
      return new Response(JSON.stringify({ error: 'basePrice (number) required for generate' }), { status: 400 });
    }

    const rng = seed ? mulberry32(seed) : Math.random;
    const nowMs = Date.now();
    const startTs = nowMs - minutes * 60 * 1000; // start time in ms

    const rows: any[] = [];
    let lastPrice = basePrice;

    for (let i = 0; i < minutes; i++) {
      const t = startTs + i * 60 * 1000; // minute ticks
      const open = lastPrice;
      // small random walk scaled to price
      const changePct = (rng() - 0.5) * 0.002; // ±0.1% typical per minute
      const close = +(open * (1 + changePct)).toFixed(8);
      const high = +(Math.max(open, close) * (1 + rng() * 0.001)).toFixed(8);
      const low = +(Math.min(open, close) * (1 - rng() * 0.001)).toFixed(8);
      const volume = +(Math.max(1, 50 * rng())).toFixed(4);

      rows.push({
        trading_pair: pair,
        time: Math.floor(t),
        open,
        high,
        low,
        close,
        volume,
        is_intervened: false,
        created_at: new Date(t).toISOString()
      });

      lastPrice = close;
    }

    // Bulk insert in chunks
    const CHUNK = 500;
    for (let i = 0; i < rows.length; i += CHUNK) {
      const slice = rows.slice(i, i + CHUNK);
      const { error } = await supabase.from('market_kline_data').upsert(slice, { onConflict: ['trading_pair','time'], returning: 'minimal' });
      if (error) {
        console.error('Supabase upsert error', error);
        return new Response(JSON.stringify({ error: error.message }), { status: 500 });
      }
    }

    return new Response(JSON.stringify({ ok: true, inserted: rows.length }), { status: 200 });

  } catch (err) {
    console.error('initialize-market-kline error', err);
    return new Response(JSON.stringify({ error: String(err) }), { status: 500 });
  }
}

使用方式（两个常见场景）
场景 A：服务端生成 4 小时的模拟 K 线（冷启动）
curl -X POST "https://<YOUR_PROJECT>.functions.supabase.co/initialize-market-kline" \
  -H "Authorization: Bearer <SERVICE_ROLE_KEY>" \
  -H "Content-Type: application/json" \
  -d '{
    "mode":"generate",
    "pair":"BTC/USDT",
    "minutes":240,
    "basePrice":30000,
    "seed": 12345
  }'


返回 { ok: true, inserted: 240 } 表示已写入 240 条分钟线到 market_kline_data。

场景 B：批量上传第三方历史数据（JSON）
curl -X POST "https://<YOUR_PROJECT>.functions.supabase.co/initialize-market-kline" \
  -H "Authorization: Bearer <SERVICE_ROLE_KEY>" \
  -H "Content-Type: application/json" \
  -d '{
    "mode":"upload",
    "pair":"BTC/USDT",
    "data":[
       {"time":1692624000000,"open":30000,"high":30100,"low":29950,"close":30050,"volume":120},
       {"time":1692624060000,"open":30050,"high":30080,"low":30010,"close":30030,"volume":80}
       // ...更多
    ]
  }'


适合你把第三方历史 API（或 CSV 转 JSON）先在后端抓取并传入该函数，一次性批量导入。

为什么这样做（回到你的目标）

把繁重的“生成/导入”逻辑放到服务器端：避免在客户端循环生成上千条记录导致卡死。

灵活两用：既可生成临时模拟数据（快速启动），也能导入真实历史数据（更精准）。

与后续“延迟覆盖/干预”工作流无缝对接：一旦 market_kline_data 有数据，后端延迟 worker 就能把 market_kline_raw 按策略合并/覆盖并写入同表（或新增列 is_intervened），前端直接订阅显示。

部署小贴士 & 注意事项

环境变量：在 Supabase Functions 的设置中注入 SUPABASE_URL 与 SUPABASE_SERVICE_ROLE_KEY（只在后端/函数使用）。

权限：market_kline_data 表需要允许 service role 写入（service role 默认有全权限）。前端只需要可读规则（或用 RLS 规则细化）。

大数据量：上传非常长的历史（>100k 行）时请分批上传以免超时。上面函数对上传分块处理。

时间格式：这里 time 我保留为毫秒（unix ms）。前端/你的现有代码里如果使用秒(ms->s 转换要注意）。

干预对接：当你准备把“干预逻辑”放到后端时，这个函数可做为数据来源的一部分：先生成/导入，再让 delay-worker 按需覆盖。

阿义，接下来我可以帮你做任意一项（我推荐按优先级）：

把上面 Edge Function 的 部署 README（包含在 Supabase 控制台如何创建 Function、如何设置 Scheduler、如何测试的截图指令化步骤）写成 Markdown，方便交付运维。